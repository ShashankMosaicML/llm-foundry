max_seq_len: 4096 
seed: 1
precision: amp_fp16

models:
-
  model_name: mosaicml/mpt-7b-chat-8k
  model:
    name: hf_causal_lm
    pretrained_model_name_or_path: moa saicml/mpt-7b-chat-8k
    init_device: cpu
    pretrained: true
  tokenizer:
    name: mosaicml/mpt-7b-chat-8k
    kwargs:
      model_max_length: ${max_seq_len}

device_eval_batch_size: 4

# FSDP config for model sharding
fsdp_config:
  sharding_strategy: FULL_SHARD
  mixed_precision: FULL

icl_tasks:
-
  label: hotpot_qa_long_context_4k
  dataset_uri: eval/local_data/long_context/hotpot_train_v1.1_context_len_4096_tokenizer_gpt-4.jsonl
  num_fewshot: [0]
  icl_task_type: language_modeling
# -
#   label: piqa
#   dataset_uri: eval/local_data/commonsense_reasoning/piqa.jsonl  # ADD YOUR OWN DATASET URI
#   num_fewshot: [10]
#   icl_task_type: multiple_choice
#   continuation_delimiter: "\nAnswer: " # this separates questions from answers

# model_gauntlet: 'eval/yamls/model_gauntlet.yaml'